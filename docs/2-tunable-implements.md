# Tunable Implements

## Search Space
A sparse operator incorperates one or more computing kernels, and each kernel may have multiple *implementation*s. The implementations could be hand-crafted efficient kernels (templates or libraries), or codes generated by other tools (e.g., TVM). The kernel can select one of the implements according to their performance. And each implementation could have tunable parameters, such as tiling size. The tuner could combine the each implementation's search space into a nested search space.

```python
>>> sparse_operator.get_search_space()
>>> {
        'kernel-0': TunableItemCfg('choice', _is_nested=True, _value={
            'impl-A': {
                'A1': TunableItemCfg('choice', _value=[a1,a2,a3]),
                'A2': TunableItemCfg('choice', _value=[a4,a5,a6]),
            },
            'impl-B': {
                'B1': TunableItemCfg('choice', _value=[b1,b2,b3]),
                'B2': TunableItemCfg('choice', _value=[b4,b5,b6]),
            },
        }),
    }
```

<!--
The tuner (based on [NNI](https://github.com/microsoft/nni)) is instance of [sparta.common.tuning.Tunable](reference/tuning.rst). It could generate samples from the search space based on algorithms such as [Grid Search](https://nni.readthedocs.io/en/stable/reference/hpo.html#nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner), [Random Search](https://nni.readthedocs.io/en/stable/reference/hpo.html#nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner), [TPE](https://nni.readthedocs.io/en/stable/reference/hpo.html#nni.algorithms.hpo.tpe_tuner.TpeTuner), *etc*.
-->

## Connections between Tunable Items

If two kernels are connected by a sparse tensor that binds some tunable parameters, SparTA will record those cross-kernel-connected paramters for more operations in tuners.

## Tuners

The tuner repetitively generates samples from the search space and finally returns the best config. Only grid-search and random-search tuning algorithms are supported now.
