{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Linear Networks\n",
    "\n",
    "This is an example of how to build a sparse DNN to do simple image classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sparta\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda:0'\n",
    "random_seed = 2022\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation\n",
    "1. Download the MNIST dataset through `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = [\n",
    "    torchvision.datasets.MNIST(\n",
    "        root=\"\",\n",
    "        train=training,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]),\n",
    "    )\n",
    "    for training in [True, False]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocess: shuffle and reconstruct data with batch size of 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "def preprocess(dataset):\n",
    "    indexes = [i for i in range(len(dataset))]\n",
    "    np.random.shuffle(indexes)\n",
    "    batches = []\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        X_list, y_list = [], []\n",
    "        for j in range(batch_size):\n",
    "            X, y = dataset[indexes[i * batch_size + j]]\n",
    "            X_list.append(X.view(1, 28 * 28))\n",
    "            y_list.append(y)\n",
    "        batches.append((torch.vstack(X_list).contiguous(), torch.tensor(y_list)))\n",
    "    return batches\n",
    "\n",
    "train_set = preprocess(train_set)\n",
    "test_set = preprocess(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define training and testing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_func = torch.nn.functional.nll_loss\n",
    "\n",
    "def train(model, epochs=20):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    start.record()\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in train_set:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X.to(device))\n",
    "            loss = loss_func(output, y.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    time_cost = start.elapsed_time(end) / 1000\n",
    "    print(f'Training time cost: {round(time_cost, 3)} s')\n",
    "\n",
    "def test(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_set:\n",
    "            if X.shape[0] < batch_size:\n",
    "                continue\n",
    "            output = model(X.to(device))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total +=1\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Accuracy: {round(accuracy, 3)}%\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Network\n",
    "1. Create a 4-layer dense neural network with `torch.nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_0 = torch.nn.Linear(28 * 28, 2048, device=device)\n",
    "        self.linear_1 = torch.nn.Linear(2048, 4096, device=device)\n",
    "        self.linear_2 = torch.nn.Linear(4096, 2048, device=device)\n",
    "        self.linear_3 = torch.nn.Linear(2048, 10, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear_0(x))\n",
    "        x = torch.relu(self.linear_1(x))\n",
    "        x = torch.relu(self.linear_2(x))\n",
    "        x = torch.log_softmax(self.linear_3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "dense_net = DenseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the dense network for 20 epochs and test. We will get ~98.1% accuracy after ~20 seconds' training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dense Network =====\n",
      "Training time cost: 20.31 s\n",
      "Accuracy: 98.096%\n"
     ]
    }
   ],
   "source": [
    "print('===== Dense Network =====')\n",
    "train(dense_net, epochs=20)\n",
    "test(dense_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Network\n",
    "1. Create a 4-layer neural network of the same shape with our `DenseNet`. The middle two FC layers are 90% sparsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        mask = sparta.testing.block_mask((4096, 2048), block=(32, 32), sparsity=0.9, device=device)\n",
    "        self.linear_0 = torch.nn.Linear(28 * 28, 2048, device=device)\n",
    "        self.linear_1 = sparta.nn.SparseLinear(\n",
    "            torch.nn.Linear(2048, 4096, device=device),\n",
    "            weight_mask=mask,\n",
    "        )\n",
    "        self.linear_2 = sparta.nn.SparseLinear(\n",
    "            torch.nn.Linear(4096, 2048, device=device),\n",
    "            weight_mask=mask.T,\n",
    "        )\n",
    "        self.linear_3 = torch.nn.Linear(2048, 10, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear_0(x))\n",
    "        x = torch.relu(self.linear_1(x))\n",
    "        x = torch.relu(self.linear_2(x))\n",
    "        x = torch.log_softmax(self.linear_3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "sparse_net = SparseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tune the sparse network with sample inputs and gradients. Note that we need to set `backward_weight=1` to activate backward kernels in tuning. This step may take 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.rand((batch_size, 28 * 28), device=device)\n",
    "sample_grad = torch.rand((batch_size, 10), device=device)\n",
    "\n",
    "# The tune() function will find the best config,\n",
    "# build the sparse operator and return the best config.\n",
    "best_config = sparta.nn.tune(\n",
    "    sparse_net,\n",
    "    sample_inputs=[sample_input],\n",
    "    sample_grads=[sample_grad],\n",
    "    backward_weight=1,\n",
    "    algo='rand',\n",
    "    max_trials=30,\n",
    ")\n",
    "\n",
    "# If you have already tuned once and saved the best config,\n",
    "# you can skip the tune() step and build the operator directly.\n",
    "sparta.nn.build(\n",
    "    sparse_net,\n",
    "    sample_inputs=[sample_input],\n",
    "    configs=best_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the sparse network for 20 epochs and test. This time we will get ~97.5% accuracy after ~8 seconds' training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Sparse Network =====\n",
      "Training time cost: 7.598 s\n",
      "Accuracy: 97.607%\n"
     ]
    }
   ],
   "source": [
    "print('===== Sparse Network =====')\n",
    "train(sparse_net, epochs=20)\n",
    "test(sparse_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c648f235a6034420253553732dbe431468efa26b97e5b938450249de7084a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
